<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>SUNGHO KIM</title>
    <description>Data Science Portfolio</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Thu, 14 Sep 2017 22:03:00 -0400</pubDate>
    <lastBuildDate>Thu, 14 Sep 2017 22:03:00 -0400</lastBuildDate>
    <generator>Jekyll v3.5.2</generator>
    
      <item>
        <title>Spotify</title>
        <description>
</description>
        <pubDate>Tue, 05 Sep 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2017/09/05/spotify/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/09/05/spotify/</guid>
        
        
      </item>
    
      <item>
        <title>Who should FC Barcelona buy ?</title>
        <description>

Over this summer, there was a record-breaking deal in the soccer transfer market. Paris Saint-Germain triggered Neymar ’s release clause and paid €222 million to FC Barcelona. Last year, Paul Pogba’s deal from Juventus to Manchester United was a record-breaking, and the amount was €222. The transfer values just have increased exponentially.

In this post, I am not going to talk about if the value of Neymar is worth it or not, but how FC Barcelona should invest money from Neymar’s fee in finding his successor. I am going to use the K-nearest neighbors(KNN) algorithm to find out which soccer players who have capabilities to replace “Neymar” based on the player’s stats from last season (2016-2017 season). I did not include Cristiano Ronaldo or other real madrid players in the datset, because there is a huge rivalry between Real Madrid and FC Barcelona that players from Real Madrid would move to FC Barcelona.

First, normalize the dataset, then find the Euclidian distance between Neymar(target) and the other players. Since we are looking for a player that is most similar to Neymar, we should find the second most similar to Neymar. The distance between Neymar to Neymar is 0.

import pandas as pd
import math

soccer = pd.read_csv(&quot;2016.csv&quot;)
selected_player = soccer[soccer[&quot;player&quot;] == &quot;Neymar&quot;].iloc[0]

soccer_numeric = soccer[distance_columns]
soccer_normalized = (soccer_numeric - soccer_numeric.mean()) / soccer_numeric.std()

from scipy.spatial import distance
neymar_normalized = soccer_normalized[soccer[&quot;player&quot;] == &quot;Neymar&quot;]
euclidean_distances = soccer_normalized.apply(lambda row: distance.euclidean(row, neymar_normalized), axis=1)

distance_frame = pd.DataFrame(data={&quot;dist&quot;: euclidean_distances, &quot;idx&quot;: euclidean_distances.index})
distance_frame = distance_frame.sort_values([&quot;dist&quot;], ascending=True)

second_smallest = distance_frame.iloc[1][&quot;idx&quot;]
most_similar_to_neymar = soccer.loc[int(second_smallest)][&quot;player&quot;]
print(most_similar_to_neymar)


As a result of the analysis, it seems like Philippe Coutinho is most similar to Neymar. Angel Di Maria and Paulo Dybala are the second, third similar to Neymar respectively. According to the media, FC Barcelona actually had tried to buy Philippe Coutinho and Angel Di Maria before the transfer window closed. However, none of those deals happened, and FC Barcelona ended up signing Ousmane Dembele to replace Neymar.
</description>
        <pubDate>Fri, 01 Sep 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2017/09/01/neymar/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/09/01/neymar/</guid>
        
        
      </item>
    
      <item>
        <title>Exploring Chipotle Order Data</title>
        <description>This data is based on about 1,800 Grubhub orders from July to December 2012. The data was collected from two Chipotle restaurants in Wahsington D.C &amp;amp; East Lansing. It seemed interesting for me to explore the dataset by asking questions like what items people order the most, what is the average order price, etc. I am going to use python to analyze the data.

First, Load the tsv file using Pandas and print(df.head(10)) to see the format of data and first 10 items on the list. I recommend you to do this on every data set, before you execute any commands on the data.

As you can see from table, the data is described by order_id, quantity, item_name, choice_descrptiption and price. Let’s try to look at which item is most ordered by people on the list. You can use matplotlib.pyplot to visualize the data.

import pandas as pd
df = pd.read_table('orders.tsv')
print(df.head(10))

import matplotlib.pyplot as plt
items = df.item_name.value_counts().plot(kind=&quot;bar&quot;)
plt.show()




It seems like the most popular item is the “Chicken Bowl” and the least ordered items are the “Carnitas Salad” and the “Veggie Crispy Tacos”. Besides the “Chicken Bowl”, I am curious as to what other items are most ordered. Let’s zoom in on the graph a little bit closer and see what those are. To do this, type the following command.

top10 = df.item_name.value_counts()[:10].plot(kind=&quot;bar&quot;)
plt.show()




Now you can see the name of the items more clearly than before. If you look at the graph, it is interesting to see that two items (Canned Soda, bottled water) from the top 10 are beverages. Let’s look at what kind of canned soda people ordered the most.  It is interesting to see that Mountain Dew and Dr.Pepper ranked second and third respectively.

df['item_price'] = df['item_price'].str.replace('$','')  
df['item_price'] = df['item_price'].astype(float)
orders = df.groupby('order_id').sum()  
print(orders.head())




It was intriguing to explore the items that are most ordered by customers at Chipolte. Now, let’s try to look at the data from a business perspective and explore the data of price per order. First, you have to replace “$” with “” and change the data type to “float” in “item_price column”, because we would like to analyzes the numbers, instead of strings.

descriptions = df.groupby([&quot;item_name&quot;, &quot;choice_description&quot;])[&quot;order_id&quot;].count().reset_index(name=&quot;count&quot;)
descriptions = descriptions[descriptions['item_name'].str.contains(&quot;Canned Soda&quot;)]  
descriptions.sort_values('count',ascending=False)
print(descriptions)

descriptions.choice_description.value_counts().plot(kind=&quot;bar&quot;)
plt.show()


On average, it looks like people tend to spend 18.81 dollars per order. The minimum is 10.08 dollars per order and the maximum is 205 dollars per order. It is quite incredible to see that there are people who order 205 dollars worth of chipotle at a time. Maybe that person is catering a party or some other sort or large gathering.



It was fun exploring the data and finding a trend. I am planning to post more like this in the future. If you have any questions, feedback, advice or corrections please get in touch with me on Linkedin or email me at sunghokim@wustl.edu. I referred to this blog to write this post.

</description>
        <pubDate>Sun, 20 Aug 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2017/08/20/chipotle/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/08/20/chipotle/</guid>
        
        
      </item>
    
      <item>
        <title>Mapping NYC Motor Vehicle Collisions Data</title>
        <description>

Everyday when I walk around NYC, I see a lot of traffic and sometimes car accidents on the street. This made me wonder if there are certain spots where car accidents happen more frequently than others. If there are patterns, I thought it would be fun to visualize and show them on the map. To solve my curiosity, I organized the procedures as following.


  Find the dataset
  Clean the dataset for mapping
  Visualize the dataset on Google map.


Finding the dataset
As always, choosing the right dataset is the hardest problem in the data
analysis process. However, I was able to find the dataset called “NYPD Motor Vehicle Collisions” from NYC Open Data website. It provides open data for people to use and explore for free. It not only provides city government or transportation data, but also education, business and more. So if you are interested what is happening around the town, I highly recommend you to take a look at the data and explore.

Cleaning the dataset 
The dataset has more than 10 columns and one million rows. If I mapped all million locations, the map would look like a Yayoi Kusama’s art work rather than a map. So I decided to reduce my dataset and focus on accidents that occurred in the last 3 months.

First, drop all the rows that have “NA” Second, select the columns that are needed for mapping (“LATIUDE” &amp;amp; “LONGTITUDE”) Third, make new column called “coordinate” that represents the spot. Finally, make another column called “frequency” which represents the frequency of coordinate.

import gmplot 
import datetime
import pandas as pd
import matplotlib.pyplot as plt  


df = pd.read_csv(&quot;2017.csv&quot;)
df = df.dropna(axis=0)

df[&quot;LATITUDE&quot;] = df[&quot;LATITUDE&quot;].astype(float)
df[&quot;LONGITUDE&quot;] = df[&quot;LONGITUDE&quot;].astype(float)
df = df[[&quot;LATITUDE&quot;,&quot;LONGITUDE&quot;]]
df.columns =[&quot;lat&quot;,&quot;long&quot;]

df[&quot;coordinate&quot;] = list(zip(df.lat, df.long))
df['freq'] = df.groupby('coordinate')['coordinate'].transform('count')


3.Visaulization 
I chose the color of the scatter spot by its frequency in the dataset.
Yellow (1~3), Green (4~9), Orange(10~17), Red (18~)

mapping = df[[&quot;lat&quot;,&quot;long&quot;,&quot;freq&quot;]]

yellow = mapping[mapping[&quot;freq&quot;]&amp;lt;=3] 
green  = mapping[(mapping[&quot;freq&quot;]&amp;gt;3) &amp;amp; (mapping[&quot;freq&quot;]&amp;lt;10)]
orange = mapping[(mapping[&quot;freq&quot;]&amp;lt;18) &amp;amp; (mapping[&quot;freq&quot;]&amp;gt;=10)]
red    = mapping[mapping[&quot;freq&quot;]&amp;gt;17] 

gmap = gmplot.GoogleMapPlotter(&quot;Latitude&quot;,&quot;Longitude&quot;, 12)
gmap.scatter(yellow.lat,yellow.long, &quot;yellow&quot; , size=15, marker=False)  
gmap.scatter(green.lat,green.long, &quot;green&quot; , size=20, marker=False)  
gmap.scatter(orange.lat,orange.long, &quot;orange&quot; , size=25, marker=False)  
gmap.scatter(red.lat,red.long, &quot;red&quot; , size=25, marker=False)


I hope you enjoyed this post, and please let me know if you have any questions, or feedback. You can reach me on Linkedin or email me at sunghokim@wustl.edu.
</description>
        <pubDate>Sat, 05 Aug 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/2017/08/05/nyc_taxi/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/08/05/nyc_taxi/</guid>
        
        
      </item>
    
  </channel>
</rss>
