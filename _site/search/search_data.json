{
  

    "2017-08-20-chipotle": {
      "title": "Exploring Chipotle Order Data",
      "content"	 : "This data is based on about 1,800 Grubhub orders from July to December 2012. The data was collected from two Chipotle restaurants in Wahsington D.C &amp;amp; East Lansing. It seemed interesting for me to explore the dataset by asking questions like what items people order the most, what is the average order price, etc. I am going to use python to analyze the data.First, Load the tsv file using Pandas and print(df.head(10)) to see the format of data and first 10 items on the list. I recommend you to do this on every data set, before you execute any commands on the data.As you can see from table, the data is described by order_id, quantity, item_name, choice_descrptiption and price. Let’s try to look at which item is most ordered by people on the list. You can use matplotlib.pyplot to visualize the data.import pandas as pddf = pd.read_table(&#39;orders.tsv&#39;)print(df.head(10))import matplotlib.pyplot as pltitems = df.item_name.value_counts().plot(kind=&quot;bar&quot;)plt.show()It seems like the most popular item is the “Chicken Bowl” and the least ordered items are the “Carnitas Salad” and the “Veggie Crispy Tacos”. Besides the “Chicken Bowl”, I am curious as to what other items are most ordered. Let’s zoom in on the graph a little bit closer and see what those are. To do this, type the following command.top10 = df.item_name.value_counts()[:10].plot(kind=&quot;bar&quot;)plt.show()Now you can see the name of the items more clearly than before. If you look at the graph, it is interesting to see that two items (Canned Soda, bottled water) from the top 10 are beverages. Let’s look at what kind of canned soda people ordered the most.  It is interesting to see that Mountain Dew and Dr.Pepper ranked second and third respectively.df[&#39;item_price&#39;] = df[&#39;item_price&#39;].str.replace(&#39;$&#39;,&#39;&#39;)  df[&#39;item_price&#39;] = df[&#39;item_price&#39;].astype(float)orders = df.groupby(&#39;order_id&#39;).sum()  print(orders.head())It was intriguing to explore the items that are most ordered by customers at Chipolte. Now, let’s try to look at the data from a business perspective and explore the data of price per order. First, you have to replace “$” with “” and change the data type to “float” in “item_price column”, because we would like to analyzes the numbers, instead of strings.descriptions = df.groupby([&quot;item_name&quot;, &quot;choice_description&quot;])[&quot;order_id&quot;].count().reset_index(name=&quot;count&quot;)descriptions = descriptions[descriptions[&#39;item_name&#39;].str.contains(&quot;Canned Soda&quot;)]  descriptions.sort_values(&#39;count&#39;,ascending=False)print(descriptions)descriptions.choice_description.value_counts().plot(kind=&quot;bar&quot;)plt.show()On average, it looks like people tend to spend 18.81 dollars per order. The minimum is 10.08 dollars per order and the maximum is 205 dollars per order. It is quite incredible to see that there are people who order 205 dollars worth of chipotle at a time. Maybe that person is catering a party or some other sort or large gathering.It was fun exploring the data and finding a trend. I am planning to post more like this in the future. If you have any questions, feedback, advice or corrections please get in touch with me on Linkedin or email me at sunghokim@wustl.edu. I referred to this blog to write this post.",
      "url": "/2017/08/20/chipotle/",
      "author": "Sungho Kim",
      "categories": ""
    }
    ,
  

    "2017-08-15-nba-knn": {
      "title": "Clustering NBA Players",
      "content"	 : "In this post, we’ll be using the K-nearest neighbors algorithm and euclidean distance to figure out figure out which NBA players are the most similar to Lebron James. I foudn out that Kemba Walker is the most simlar player to Lebron James according to the NBA data from 16-17 season.import pandas as pdimport mathnba = pd.read_csv(&amp;quot;nba17.csv&amp;quot;)# Lebron James# Select only the numeric columns from the NBA datasetnba_numeric = nba[distance_columns]# Normalize all of the numeric columnsnba_normalized = (nba_numeric - nba_numeric.mean()) / nba_numeric.std()from scipy.spatial import distance# Fill in NA values in nba_normalizednba_normalized.fillna(0, inplace=True)# Find the normalized vector for lebron james.lebron_normalized = nba_normalized[nba[&amp;quot;player&amp;quot;] == &amp;quot;Lebron James&amp;quot;]# Find the distance between lebron james and everyone else.euclidean_distances = nba_normalized.apply(lambda row: distance.euclidean(row, lebron_normalized), axis=1)# Create a new dataframe with distances.distance_frame = pd.DataFrame(data={&amp;quot;dist&amp;quot;: euclidean_distances, &amp;quot;idx&amp;quot;: euclidean_distances.index})distance_frame = distance_frame.sort_values([&amp;quot;dist&amp;quot;], ascending=True)print(distance_frame)# Find the most similar player to lebron (the lowest distance to lebron is lebron, the second smallest is the most similar non-lebron player)second_smallest = distance_frame.iloc[1][&amp;quot;idx&amp;quot;]most_similar_to_lebron = nba.loc[int(second_smallest)][&amp;quot;player&amp;quot;]print(most_similar_to_lebron )",
      "url": "/2017/08/15/nba_knn/",
      "author": "Sungho Kim",
      "categories": ""
    }
    ,
  

    "2017-08-05-nyc-taxi": {
      "title": "Mapping NYC Motor Vehicle Collisions Data",
      "content"	 : "Everyday when I walk around NYC, I see a lot of traffic and sometimes car accidents on the street. This made me wonder if there are certain spots where car accidents happen more frequently than others. If there are patterns, I thought it would be fun to visualize and show them on the map. To solve my curiosity, I organized the procedures as following.  Find the dataset  Clean the dataset for mapping  Visualize the dataset on Google map.Finding the datasetAs always, choosing the right dataset is the hardest problem in the dataanalysis process. However, I was able to find the dataset called “NYPD Motor Vehicle Collisions” from NYC Open Data website. It provides open data for people to use and explore for free. It not only provides city government or transportation data, but also education, business and more. So if you are interested what is happening around the town, I highly recommend you to take a look at the data and explore.Cleaning the dataset The dataset has more than 10 columns and one million rows. If I mapped all million locations, the map would look like a Yayoi Kusama’s art work rather than a map. So I decided to reduce my dataset and focus on accidents that occurred in the last 3 months.First, drop all the rows that have “NA” Second, select the columns that are needed for mapping (“LATIUDE” &amp;amp; “LONGTITUDE”) Third, make new column called “coordinate” that represents the spot. Finally, make another column called “frequency” which represents the frequency of coordinate.import gmplot import datetimeimport pandas as pdimport matplotlib.pyplot as plt  df = pd.read_csv(&quot;2017.csv&quot;)df = df.dropna(axis=0)df[&quot;LATITUDE&quot;] = df[&quot;LATITUDE&quot;].astype(float)df[&quot;LONGITUDE&quot;] = df[&quot;LONGITUDE&quot;].astype(float)df = df[[&quot;LATITUDE&quot;,&quot;LONGITUDE&quot;]]df.columns =[&quot;lat&quot;,&quot;long&quot;]df[&quot;coordinate&quot;] = list(zip(df.lat, df.long))df[&#39;freq&#39;] = df.groupby(&#39;coordinate&#39;)[&#39;coordinate&#39;].transform(&#39;count&#39;)3.Visaulization I chose the color of the scatter spot by its frequency in the dataset.Yellow (1~3), Green (4~9), Orange(10~17), Red (18~)mapping = df[[&quot;lat&quot;,&quot;long&quot;,&quot;freq&quot;]]yellow = mapping[mapping[&quot;freq&quot;]&amp;lt;=3] green  = mapping[(mapping[&quot;freq&quot;]&amp;gt;3) &amp;amp; (mapping[&quot;freq&quot;]&amp;lt;10)]orange = mapping[(mapping[&quot;freq&quot;]&amp;lt;18) &amp;amp; (mapping[&quot;freq&quot;]&amp;gt;=10)]red    = mapping[mapping[&quot;freq&quot;]&amp;gt;17] gmap = gmplot.GoogleMapPlotter(&quot;Latitude&quot;,&quot;Longitude&quot;, 12)gmap.scatter(yellow.lat,yellow.long, &quot;yellow&quot; , size=15, marker=False)  gmap.scatter(green.lat,green.long, &quot;green&quot; , size=20, marker=False)  gmap.scatter(orange.lat,orange.long, &quot;orange&quot; , size=25, marker=False)  gmap.scatter(red.lat,red.long, &quot;red&quot; , size=25, marker=False)I hope you enjoyed this post, and please let me know if you have any questions, or feedback. You can reach me on Linkedin or email me at sunghokim@wustl.edu.",
      "url": "/2017/08/05/nyc_taxi/",
      "author": "Sungho Kim",
      "categories": ""
    }
    
  

  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
}